# 第一次任务

## Day0
### 任务内容：
阅读自动驾驶安全相关的文献，两周内写一个总结报告
跑自动驾驶程序的demo

### 课程目标：
自动驾驶目标的欺骗与对抗：比如，车牌号的检测逃逸/路标的检测逃逸。
通俗的说，本来车牌号能被摄像头的识别程序识别出来，通过欺骗方 法，让车牌号检测不出来；本来红绿灯能检测出来，欺骗以后检测不出来；本来路上的线提示要右拐了，欺骗以后就识别不出拐弯线。

### 推荐书籍：
 ·《机器学习与安全》
 
 
 ·《AI安全与对抗样本入门》 
 
 
 ·《网络空间欺骗》 
 
 
 ·《动态目标防御》
 
 ### 我的疑问：
 欺骗是什么，怎么做到的，可以用哪些方法，如何检验
 
 ## Day1
 ### 自动驾驶汽车的欺骗：
 通过一些措施使自动驾驶程序无法正常运行，比如识别错限速车标[1]，误读路况中的障碍物导致停车[2]，
 错误的认为绿灯是红灯导致自动驾驶汽车停止[2]等等。具体措施：给路标贴电子胶带，在路上放平面广告等等。

 ### 深度学习的脆弱性：
 1.偷取模型 2.数据投毒 3.对抗样本（白盒攻击，黑盒攻击，真实世界/物理攻击）
 ### 常见检测和加固方法：
 检测过程：即为发起攻击的过程 
 #### 基于白盒：
 ILCM（最相似替代算法）
 
 
 FGSM（快速梯度算法）
 
 
 BIM（基础迭代算法）
 
 
 JSMA（显著图攻击算法）
 
 
 DeepFool（DeepFool算法）
 
 
 C/W（C/W算法）
 #### 黑盒攻击方法：
 Single Pixel Attack（单像素攻击），Local Search Attack（本地搜索攻击）
 ### 深度学习脆弱性加固



 ### 参考文献：
 [1]: 新浪科技 《研究人员骗过特斯拉汽车：把35英里限速看成85英里》 url:http://www.techweb.com.cn/internet/2020-02-20/2777981.shtml
 
 
 [2]:生物学谢博士 《自动驾驶汽车感知曝漏洞：很容易被假路标欺骗》url:https://baijiahao.baidu.com/s?id=1660646822297982069&wfr=spider&for=pc
 
