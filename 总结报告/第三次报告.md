## 概述
周一：知乎学生党可以使用的gpu服务器，最后选择了mistgpu，为了测试一下好不好用，首先跑了Ghostbusters模型，然后很快的跑完了10s的视频，具体时间没有计算

周二，周三：上次跑lisa-faster-cnn时候，觉得别人的模型不好用，于是想自己跑模型。然后自己再GTSRB数据集上训练了一个CNN，并保存了模型文件。

周四，周五：我突然意识到GTSRB数据集是德国的交通标志数据集，看不懂。于是下载了国内的tsrd数据集，预处理过后在上个CNN中又跑了一遍。

周六，周天：跑完CNN之后我想到跑模型是想要在目标检测算法中使用，可我跑的模型好像并不能用，于是决定在Faster-RCNN上训练自己的数据集。到目前为止，faster-rcnn已经配置好，labelImg能
正常使用，接下来就是朴实的手造数据集的工作了。

这次报告主要是为了总结一下这周的工作，并希望老师可以给出指导意见。
## 数据集
在网上看到有大佬汇总了自动驾驶的数据集，所以我找数据集的时候都会先翻阅他的博客：<https://blog.csdn.net/weixin_42419002/article/details/100605115>

### GTSRB数据集
链接：<http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset>

下载链接：<https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/published-archive.html>

我选择的是Final_Traing_Images，数据集包含42个类别的交通标志文件夹，每个文件夹里有ppm格式的文件以及一个包含交通标志具体位置的csv文件。对于GTSRB数据集的处理比较粗糙，
只是将ppm转成了jpg格式的文件，具体代码如下：
```py
import os
import sys
import csv
from PIL import Image

dirs_path = os.listdir("Images/")
for imgs_path in dirs_path:
    dir_path = "Images/" + imgs_path
    imgs_path = os.listdir(dir_path)
    for img_path in imgs_path:
        img_path = dir_path + "/" + img_path
        if(img_path[-3:] == 'csv'):
            break
        img = Image.open(img_path)
        if(os.path.exists("JPGImages/" + img_path[7:12]) == False):
            os.mkdir("JPGImages/" + img_path[7:12])
        img.save("JPGImages/" + img_path[7:-4] + ".jpg")
```
### TSRD数据集
链接：<http://www.nlpr.ia.ac.cn/pal/trafficdata/recognition.html>

TSRD数据集非常的粗糙，给了一个jpg文件夹和一个Annotation文本文档（里面包含类别和交通标志具体位置的信息）。对于TSRD数据集，我首先根据Annotation文本文档裁剪出了交通标志具体的区域，
顺手制作了一个labels.txt文件用于保存每张图片对应的标签。代码如下：
```py
import cv2
import os

dir_path = "tsrd-train"
save_path = "tsrd_processd"
imgs_path = os.listdir(dir_path)
file = open("TsignRecgTrain4170Annotation.txt","r")
dict = {}
for line in file.readlines():
    l = line.split(';')
    pos = {}
    # print(l)
    pos['x0'] = int(l[3])
    pos['y0'] = int(l[4])
    pos['x1'] = int(l[5])
    pos['y1'] = int(l[6])
    pos['label'] = int(l[7])
    dict[l[0]] = pos
    str = l[0] + ',' + l[7] + '\n'
    print(str)
    with open('labels.txt','a') as f:
        f.writelines(str)

for i in imgs_path:
    img_path = os.path.join(dir_path,i)
    img = cv2.imread(img_path)
    x0 = dict[i]['x0']
    y0 = dict[i]['y0']
    x1 = dict[i]['x1']
    y1 = dict[i]['y1']
    img = img[y0:y1,x0:x1]
    img_path = os.path.join(save_path,i)
    cv2.imwrite(img_path, img)
```
## 我的卷积神经网络
模型参考了《TensorFlow机器学习》，经过不断的搜博客和自己摸索，学会了如何在tensorflow中训练自己的数据集，以及保存ckpt模型文件。

我的卷积神经网络结构比较简单，包含两层卷积，一层全连接层，一层softmax输出层。输入的图像为彩图，大小为(24,24,3)；输入的标签使用one_hot编码，深度为64。第一层卷积的输入大小为(None,24,24,3)的numpy数组，使用
(5×5)大小的64个卷积核，在3个通道上进行卷积；第二层卷积采用(5×5)大小的64个卷积核，在64个维度上进行卷积。损失函数采用softmax交叉熵函数。

代码中基于GTSRB和TSRD的数据集预处理稍有不同，这里只贴出训练GTSRB数据集的代码。
### train.py
```py
'''
train.py:用来训练模型
'''

import tensorflow.compat.v1 as tf
import numpy as np
import os
from tensorflow.python.framework import graph_util
from PIL import Image

tf.disable_eager_execution()
# 屏蔽waring信息
# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

batch_size = 512
epoch_num = None
epochs = 1000

# pd_file_path = "my_graph.pb"
# g = tf.Graph()

# 划分数据集
def split_dataset(x_dataset, y_dataset, ratio):
    arr = np.arange(len(x_dataset))
    np.random.shuffle(arr)
    x_ = []
    for i in x_dataset:
        img = read_img(i)
        x_.append(img)
        # print(len(x_))
    x_dataset = np.array(x_)
    num_train = int(len(x_dataset) * ratio)
    x_train = x_dataset[arr[0:num_train]]
    x_test = x_dataset[arr[num_train:x_dataset.size]]
    y_train = y_dataset[arr[0:num_train]]
    y_test = y_dataset[arr[num_train:y_dataset.size]]
    return x_train,x_test,y_train,y_test

# 读取图像
def read_img(img_name):
    image = Image.open(img_name)
    image = image.resize((24,24))
    image = np.array(image)
    # image = tf.image.decode_jpeg(image)
    # image = tf.image.resize_images(image, [64,64])
    # image = tf.image.per_image_standardization(image)
    return image

# 创建数据集
def create_dataset(path):
    '''
    :param path: 图像所在的文件夹
    :return: 图像路径list，one_hot编码的list
    '''
    files = os.listdir(path)
    img_names = []
    labels = []
    index = 0
    for f in files:
        print(f,index)
        img_dir = os.path.join(path ,f)
        imgs_path = os.listdir(img_dir)
        for i in imgs_path:
            img_names.append(os.path.join(img_dir, i))
            labels.append(index)
        index += 1

    # img_names = tf.convert_to_tensor(img_names, dtype=tf.string)
    # labels = tf.convert_to_tensor(labels, dtype = tf.float32)
    labels = tf.one_hot(indices = labels, depth=64 ,on_value=1,off_value=0 ,axis=-1)
    # for i in labels.eval():
    #     print(i)
    sess = tf.Session()
    vals = sess.run(labels)
    sess.close()
    # dataset = dataset.shuffle(buffer_size=800).batch(batch_size).repeat(epoch_num)
    return img_names, vals


x = tf.placeholder(tf.float32, [None,24,24,3])
y = tf.placeholder(tf.float32, [None,64])

W1 = tf.Variable(tf.random_normal([5,5,3,64])) # 64个5*5的卷积核
b1 = tf.Variable(tf.random_normal([64]))

W2 = tf.Variable(tf.random_normal([5,5,64,64]))
b2 = tf.Variable(tf.random_normal([64]))

W3 = tf.Variable(tf.random_normal([6*6*64, 1024]))
b3 = tf.Variable(tf.random_normal([1024]))

W_out = tf.Variable(tf.random_normal([1024, 64]))
b_out = tf.Variable(tf.random_normal([64]))

def conv_layer(x, W, b):
    conv = tf.nn.conv2d(x, W, strides=[1,1,1,1], padding="SAME")
    conv_with_b = tf.nn.bias_add(conv, b)
    conv_out = tf.nn.relu(conv_with_b)
    return conv_out

def maxpool_layer(conv, k=2):
    return tf.nn.max_pool(conv, ksize=[1,k,k,1], strides=[1,k,k,1], padding = "SAME")

# 定义模型
def model():
    # x_reshaped = tf.reshape(x, shape=[-1,24,24,1])
    conv_out1 = conv_layer(x, W1, b1)
    maxpool_out1 = maxpool_layer(conv_out1)
    norm1 = tf.nn.lrn(maxpool_out1, 4, bias=1.0, alpha=0.001/9.0, beta = 0.75)

    conv_out2 = conv_layer(norm1, W2, b2)
    norm2 = tf.nn.lrn(conv_out2, 4, bias = 1.0, alpha=0.001/9.0, beta=0.75)
    maxpool_out2 = maxpool_layer(norm2)

    maxpool_reshaped = tf.reshape(maxpool_out2, [-1, W3.get_shape().as_list()[0]])
    local = tf.add(tf.matmul(maxpool_reshaped, W3), b3)
    local_out = tf.nn.relu(local)

    out = tf.add(tf.matmul(local_out, W_out), b_out)
    return out

model_op = model()
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model_op, labels=y))
train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)
correct_pred = tf.equal(tf.argmax(model_op, 1), tf.argmax(y,1))
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

# 定义一个saver
saver=tf.train.Saver()

# 定义存储路径
ckpt_dir="ckpt_dir2"
if not os.path.exists(ckpt_dir):
    os.makedirs(ckpt_dir)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    imgs,val = create_dataset("JPGImages")
    x_train, x_test, y_train, y_test = split_dataset(imgs, val, 0.7)
    # writer = tf.summary.FileWriter('/tmp/logs', sess.graph)
    for epoch in range(epochs):
        # print("Epoch",epoch)
        for i in range(0, len(y_train), batch_size):
            batch_data = x_train[i:i+batch_size, :]
            batch_onehot_vals = y_train[i:i+batch_size, :]
            sess.run(train_op, feed_dict={x:batch_data, y:batch_onehot_vals})
        if (epoch+1) % 10 == 0:
        # 在划分出的测试数据集上对模型进行预测
            accuracy_val = sess.run(accuracy, feed_dict={x:x_test, y:y_test})
            print("Epoch:{} Accuracy:{}".format(epoch, accuracy_val))
        # 保存模型
        #    saver.save(sess,ckpt_dir+"/model.ckpt",global_step=epoch+1)
```
### predict.py
```py
'''
predict.py:使用训练好的模型进行预测
'''
import tensorflow.compat.v1 as tf
import numpy as np 
from PIL import Image
# from train import model,read_img
import os 
import cv2
tf.disable_eager_execution()

x = tf.placeholder(tf.float32, [None, 24,24,3])
y = tf.placeholder(tf.float32, [None, 64])

img_path = input("请输入图像路径：")
def read_img(img_name):
    image = Image.open(img_name)
    image = image.resize((24,24))
    image = np.array(image)
    # image = tf.image.decode_jpeg(image)
    # image = tf.image.resize_images(image, [64,64])
    # image = tf.image.per_image_standardization(image)
    return image

def create_dataset(path):
    '''
    :param path: 图像所在的文件夹
    :return: 图像路径list，one_hot编码的list
    '''
    files = os.listdir(path)
    img_names = []
    labels = []
    index = 0
    for f in files:
        img_dir = os.path.join(path ,f)
        imgs_path = os.listdir(img_dir)
        for i in imgs_path:
            img_names.append(os.path.join(img_dir, i))
            labels.append(index)
        index += 1

    # img_names = tf.convert_to_tensor(img_names, dtype=tf.string)
    # labels = tf.convert_to_tensor(labels, dtype = tf.float32)
    labels = tf.one_hot(indices = labels, depth=64 ,on_value=1,off_value=0 ,axis=-1)
    # for i in labels.eval():
    #     print(i)
    sess = tf.Session()
    vals = sess.run(labels)
    sess.close()
    # dataset = dataset.shuffle(buffer_size=800).batch(batch_size).repeat(epoch_num)
    return img_names, vals

x = tf.placeholder(tf.float32, [None,24,24,3])
y = tf.placeholder(tf.float32, [None,64])

W1 = tf.Variable(tf.random_normal([5,5,3,64])) # 64个5*5的卷积核
b1 = tf.Variable(tf.random_normal([64]))

W2 = tf.Variable(tf.random_normal([5,5,64,64]))
b2 = tf.Variable(tf.random_normal([64]))

W3 = tf.Variable(tf.random_normal([6*6*64, 1024]))
b3 = tf.Variable(tf.random_normal([1024]))

W_out = tf.Variable(tf.random_normal([1024, 64]))
b_out = tf.Variable(tf.random_normal([64]))

def conv_layer(x, W, b):
    conv = tf.nn.conv2d(x, W, strides=[1,1,1,1], padding="SAME")
    conv_with_b = tf.nn.bias_add(conv, b)
    conv_out = tf.nn.relu(conv_with_b)
    return conv_out

def maxpool_layer(conv, k=2):
    return tf.nn.max_pool(conv, ksize=[1,k,k,1], strides=[1,k,k,1], padding = "SAME")

def model():
    # x_reshaped = tf.reshape(x, shape=[-1,24,24,1])
    conv_out1 = conv_layer(x, W1, b1)
    maxpool_out1 = maxpool_layer(conv_out1)
    norm1 = tf.nn.lrn(maxpool_out1, 4, bias=1.0, alpha=0.001/9.0, beta = 0.75)

    conv_out2 = conv_layer(norm1, W2, b2)
    norm2 = tf.nn.lrn(conv_out2, 4, bias = 1.0, alpha=0.001/9.0, beta=0.75)
    maxpool_out2 = maxpool_layer(norm2)

    maxpool_reshaped = tf.reshape(maxpool_out2, [-1, W3.get_shape().as_list()[0]])
    local = tf.add(tf.matmul(maxpool_reshaped, W3), b3)
    local_out = tf.nn.relu(local)

    out = tf.add(tf.matmul(local_out, W_out), b_out)
    return out

img = [read_img(img_path)]
train_model = model()
predict_op = tf.argmax(train_model,1,name = "predict")
ckpt_dir = "ckpt_dir2"

saver = tf.train.Saver()
with tf.Session() as sess:
    saver.restore(sess, ckpt_dir+'/model.ckpt-700')
    # 进行预测
    predict_result = sess.run(predict_op, feed_dict={x:img})
    print("你导入的图片是：",predict_result[0])
```

## 总结
就在我写报告的过程中，我发现TSRD数据集有用于目标检测的数据集，估计这会使我的工作量大大减少了。按照我的思路，我想下一周训练好自己的Faster-RCNN，使它可以跑视频，然后之后开始策划攻击
训练好的模型。
